{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "h1 {\n",
    "    border-bottom: 2px solid;\n",
    "}\n",
    "h2 {\n",
    "    border-bottom: 1px solid;\n",
    "}\n",
    "blockquote {\n",
    "    border-left: 2px solid;\n",
    "    /* background-color: #00000488; */\n",
    "    /* filter: brightness(80%); */\n",
    "    margin-left: 2em;\n",
    "    margin-right: 2em;\n",
    "    padding: 1px 2px 1px 1em;\n",
    "}\n",
    "</style>\n",
    "\n",
    "# Assignment 7\n",
    "## Andrew Osterhout (u1317172)\n",
    "\n",
    "### Asg-7 focuses on questions graded by the mentioned TAs\n",
    "\n",
    "### Full details are in the PDF file of Asg-7\n",
    "\n",
    "### This notebook only has space for your answers\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "* * *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **AR**\n",
    "_**PLEASE NOTE:** \"a few sentences\" is typically 3-4 sentences._\n",
    "\n",
    ">\n",
    "Because the way that the string gets processed in the PDA \n",
    "  has Non-terminals placed on top of any terminals when processing a Non-terminal,\n",
    "  due to the right handed nature of PDA's caused by the nature of how stacks store data.\n",
    "Which makes the PDA process the grammars associate with the non-terminal,\n",
    "  which adds more items onto the stack\n",
    "  before processing any terminals from the string,\n",
    "  which removes items from the stack.\n",
    "Therefore, it is because `pda_rev` has far more CFG definitions that have terminals before non-terminals.\n",
    "\n",
    "## Question 1a: Answer by filling the prompts below _(5pts)_\n",
    "\n",
    "### **Prompt:** RE\n",
    "#### ANSWER: \n",
    "> ```\n",
    "    (''+1+0+(1+0)*(10+11))  \n",
    "> ```\n",
    "\n",
    "### **Prompt:** Largest `STKMAX` below 9\n",
    "#### ANSWER: \n",
    "> $9$\n",
    "\n",
    "### **Prompt:** Type of linearity compared to that in ```pda_if_sndlast_then_1```\n",
    "_**NOTE** Don't assume that left recursion is always bad. Bottom-up parsers love left-linearity; this PDA is really pursuing top-down parsing though!_\n",
    "#### ANSWER: \n",
    "> ```\n",
    "    Right-Linearity\n",
    "> ```\n",
    "\n",
    "* * *\n",
    "\n",
    "\n",
    "## Question 1b: _(5pts)_\n",
    "\n",
    "### **Prompt:** What is the RE?\n",
    "#### ANSWER: \n",
    "> ```\n",
    "    (''+0+1+(01+11)(0+1)*)\n",
    "> ```\n",
    "\n",
    "### **Prompt:** Argue that the string (`0101001`) is in that RE's language\n",
    "#### ANSWER: \n",
    ">\n",
    "It has a `1` in the second position, \n",
    "  and my RE results in a string that if it has a length of two or more characters,\n",
    "  the first two characters must be either `01` or `11`, \n",
    "  the latter of which is how the string starts.\n",
    "\n",
    "\n",
    "* * *\n",
    "\n",
    "\n",
    "## Question 1c: _(6pts)_\n",
    "\n",
    "### **Prompt:** Inherently ambiguous language's definition\n",
    "#### ANSWER: \n",
    "> \n",
    "A language is inherently ambiguous when there is no way to define an unambiguous CFG for it.\n",
    "\n",
    "### **Prompt:** Why two parses for `\"abc\"`?\n",
    "#### ANSWER: \n",
    "> \n",
    "It can take either the route of following the `MC` or `AN` rules of `S` \n",
    "  and still be accepted.  \n",
    "\n",
    "\n",
    "* * *\n",
    "\n",
    "\n",
    "## Question 1d: _(4pts)_\n",
    "\n",
    "### **Prompt:** `\"aabbbccc\"` has only one parse - why?\n",
    "#### ANSWER: \n",
    "> \n",
    "Because there is a different number of `a`'s and `b`'s, \n",
    "  and the CFG represented in the PDA `pda_inh_amb` is set up such that \n",
    "  if the number of `a`'s does not equal the number of `b`'s it can only pass\n",
    "  by using the `AN` rule from the starting grammar `S`.\n",
    "Its ambiguity only really shows up when the number of `a`'s, `b`'s & `c`s are all the same.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "* * *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **SV**\n",
    "\n",
    "## Question 2a: _(5pts)_\n",
    "_**(answer as per prompts)**_\n",
    "\n",
    "### **Prompt:** Comment-handling by lexer?\n",
    "#### ANSWER: \n",
    "> \n",
    "```py\n",
    "    def t_COMMENT(t):\n",
    "        r'\\!\\!.*'\n",
    "        print(\"Got a Jove markdown comment\")\n",
    "        pass\n",
    "        # No return value. Token discarded\n",
    "```\n",
    "It is handled as a token, \n",
    "  but one that is defined as a function rather then a default attribute.\n",
    "Using the `t_` prefix to mark/define it as a token \n",
    "  (_aka_ a terminal $\\Sigma$).\n",
    "Then because it is defined as a function rather then a normal variable,\n",
    "  it overrides the default action the parser takes \n",
    "  and replaces it with the specified instructions.\n",
    "In this case it just `pass`es on it \n",
    "  (and in teh chatty/debug version it prints that it found a comment).\n",
    "This means that everything after `!!` is not processed by the parser.\n",
    "Since the comment token is defined as the RE `!!.*` meaning everything \n",
    "  (on the line) that follows the `!!`.\n",
    "\n",
    "\n",
    "* * *\n",
    "\n",
    "\n",
    "## Question 2b: _(20pts)_\n",
    "\n",
    "**_(17 rules listed below, ignoring p_error)_ and their 1-sentence explanation. SOME ANSWERS left behind for you to serve as a guideline.**\n",
    "\n",
    "\n",
    "### **Prompt:** Describe Rules 1-17 below:\n",
    "#### **ANSWER:** The rules are literally pulled out of the `p_` functions, \n",
    "  and presented below.\n",
    "\n",
    "\n",
    "> ### Rule 1:\n",
    "```python\n",
    "    def p_you_are_hosed(t):\n",
    "        '''md : error'''\n",
    "```\n",
    "Handles errors.\n",
    "\n",
    "\n",
    "<!-- -->\n",
    "> ### Rule 2:\n",
    "```python\n",
    "    def p_dfa_md(t):\n",
    "        '''md : DFA lines'''\n",
    "```\n",
    "Processes DFA descriptions\n",
    "\n",
    "\n",
    "<!-- -->\n",
    "> ### Rule 3:\n",
    "```python\n",
    "    def p_nfa_md(t):\n",
    "        '''md : NFA lines'''\n",
    "```\n",
    "Processes NFA descriptions\n",
    "\n",
    "<!-- -->\n",
    "> ### Rule 4:\n",
    "```python\n",
    "    def p_pda_md(t):\n",
    "        '''md : PDA lines'''\n",
    "```\n",
    "Processes PDA descriptions\n",
    "\n",
    "\n",
    "<!-- -->\n",
    "> ### Rule 5:\n",
    "```python\n",
    "    def p_tm_md(t):\n",
    "        '''md : TM lines'''\n",
    "```\n",
    "Processes Turing Machine descriptions   \n",
    "\n",
    "\n",
    "\n",
    "<!-- # lines for all machine types -->\n",
    "\n",
    "> ### Rule 6:\n",
    "```python\n",
    "    def p_lines1(t):\n",
    "        '''lines : one_line'''\n",
    "```\n",
    "Handles multiple lines as being one line. \n",
    "Used for all machine types.\n",
    "\n",
    "\n",
    "<!-- -->\n",
    "> ### Rule 7:\n",
    "```python\n",
    "    def p_lines2(t):\n",
    "        '''lines : one_line lines'''\n",
    "```\n",
    "Handles multiple lines as being multiple lines,\n",
    "  processed one at a time.\n",
    "Used for all machine types.\n",
    "\n",
    "\n",
    "<!-- -->\n",
    "> ### Rule 8:\n",
    "```python\n",
    "    def p_one_line(t):\n",
    "        '''one_line : state COLON labels ARROW states'''\n",
    "```\n",
    "Handles a single line of md, \n",
    "  breaking it up into the general `state : labels -> states` format.\n",
    "That all the machine types use.\n",
    "\n",
    "\n",
    "<!-- -->\n",
    "> ### Rule 9:\n",
    "```python\n",
    "    def p_state(t):\n",
    "        '''state : ID'''\n",
    "```\n",
    "Handles the single `state` grammar as being the `ID` token.\n",
    "Used by all machine types.\n",
    "\n",
    "\n",
    "<!-- -->\n",
    "> ### Rule 10:\n",
    "```python\n",
    "    def p_states1(t):\n",
    "        '''states : state'''\n",
    "```\n",
    "Handles the multiple `states` grammar as being a single `state` grammar.\n",
    "Used by all machine types.\n",
    "\n",
    " \n",
    "<!-- -->\n",
    "> ### Rule 11:\n",
    "```python\n",
    "    def p_states2(t):\n",
    "        '''states : state COMMA states'''\n",
    "```\n",
    "Handles the multiple `states` grammar as being a single `state` grammar,\n",
    "  followed by a `COMMA` token, \n",
    "  followed by a _\"recursive reference\"_ to the multiple `states` grammar.\n",
    "Used by all non-deterministic machine types.\n",
    "\n",
    "\n",
    "<!-- -->\n",
    "> ### Rule 12:\n",
    "```python\n",
    "    def p_labels1(t):\n",
    "        '''labels : one_label'''\n",
    "```\n",
    "Handles the multiple `labels` grammar as being a single label (`one_label`) grammar.\n",
    "Used by all machine types.\n",
    "\n",
    "\n",
    "<!-- -->\n",
    "> ### Rule 13:\n",
    "```python\n",
    "    def p_labels2(t):\n",
    "        '''labels : one_label OR labels'''\n",
    "```\n",
    "Handles the multiple `labels` grammar as being a single label grammar (`one_label`),\n",
    "  followed by the `OR` token \n",
    "  (which is `|`),\n",
    "  followed by a _\"recursive reference\"_ to the multiple `lines` grammar.\n",
    "Used by all machines types.\n",
    "\n",
    "\n",
    "<!--\n",
    "    # One label is a big deal. It deals with labels for DFA, NFA, PDA, or TM\n",
    "    # A label for DFA and NFA are just ID_or_EPS\n",
    "    # A label for a PDA is ID_or_EPS , One_gamma ; Many_Gammas\n",
    "    # A label for a TM is  ID_or_B ; ID_or_B , ID  where the last ID is L,R,S\n",
    "  -->\n",
    "\n",
    "<!-- -->\n",
    "> ### Rule 14:\n",
    "```python\n",
    "    def p_one_label1(t):\n",
    "        '''one_label : ID_or_EPS_or_B'''\n",
    "```\n",
    "Handles the single label grammar (`one_label`) as being a single label item\n",
    "  with the `ID_or_EPS_or_B` grammar.\n",
    "Used by NFA and DFA machine types.\n",
    "\n",
    "\n",
    "<!-- -->\n",
    "> ### Rule 15:\n",
    "```python\n",
    "    def p_ID_or_EPS_or_B(t):\n",
    "        '''ID_or_EPS_or_B : ID | EPS | BLANK'''\n",
    "```\n",
    "Handles the `ID_or_EPS_or_B` grammar as being one of the following tokens:\n",
    "- `ID`\n",
    "- $\\varepsilon$ (`EPS`)\n",
    "- `BLANK` (any single character)\n",
    "\n",
    "> Used by NFA and DFA machine types.\n",
    "\n",
    "\n",
    "<!-- -->\n",
    "> ### Rule 16:\n",
    "```python\n",
    "    def p_one_label2(t):\n",
    "        '''one_label : ID_or_EPS_or_B COMMA ID_or_EPS_or_B SEMICOLON ID_or_EPS_or_B'''\n",
    "```\n",
    "Handles the single label grammar (`one_label`) as being a single label item \n",
    "  with the `ID_or_EPS_or_B` grammar,\n",
    "  followed by a `COMMA` token (`,`),\n",
    "  followed by another `ID_or_EPS_or_B` grammar,\n",
    "  followed by a `SEMICOLON` token (`;`),\n",
    "  followed by a final `ID_or_EPS_or_B` grammar.\n",
    "Used by the PDA machine type.\n",
    "\n",
    "\n",
    "<!-- -->\n",
    "> ### Rule 17:\n",
    "```python \n",
    "    def p_one_label3(t):\n",
    "        '''one_label : ID_or_EPS_or_B SEMICOLON ID_or_EPS_or_B COMMA ID_or_EPS_or_B''' \n",
    "```\n",
    "Handles the single label grammar (`one_label`) as being a single label item \n",
    "  with the `ID_or_EPS_or_B` grammar,\n",
    "  followed by a `SEMICOLON` token (`;`),\n",
    "  followed by another `ID_or_EPS_or_B` grammar,\n",
    "  followed by a `COMMA` token (`,`),\n",
    "  followed by a final `ID_or_EPS_or_B` grammar.\n",
    "Used by the Turing Machine (`TM`) machine type.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "* * *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **LT**\n",
    "\n",
    "## Question 3a:  The first expression evaluation's result + parsing details: _(9pts)_\n",
    "_(follow prompts)_\n",
    "\n",
    "### **Prompt:** Expression result\n",
    "#### ANSWER:\n",
    "> $45$\n",
    "\n",
    "### **Prompt:** Tokenization\n",
    "#### ANSWER: \n",
    "> - Added `'SUCC'` to the tuple `tokens`, \n",
    ">   to allow the lexer to know that there is a token represented by the string `'SUCC'`.\n",
    "> - Defined the token `t_SUCC` to be `r'\\!'` (_i.e._ the RE for `!`),\n",
    ">   to allow the lexer to know how to recognize the token in a string.\n",
    "\n",
    "\n",
    "### **Prompt:** Precedence for SUCC\n",
    "#### ANSWER: \n",
    "> - Added `('right','SUCC')` to the end of the tuple `precedence`,\n",
    ">   to allow the parser to know that it should consider the Token `'SUCC'`.\n",
    "\n",
    "\n",
    "\n",
    "### **Prompt:** Associativity for SUCC\n",
    "#### ANSWER: \n",
    "> - Added `('right','SUCC')` to the end of the tuple `precedence`,\n",
    ">   to allow the parser to know that it should associate whatever is to the right\n",
    ">   of the `'SUCC'` (`!`). <br/>\n",
    ">   (_i.e._ set the associativity of the `'SUCC'` operatotr to be right associative)\n",
    "\n",
    "\n",
    "### **Prompt:** Semantics\n",
    "#### ANSWER: \n",
    "> - Defined a function `p_expression_succ(t)` \n",
    ">   with a DOCuString `'''expression : SUCC expression'''`,\n",
    ">   to tell the parser about the grammar of how the Successor operator works.\n",
    "> - In the function I have the instruction to set the result value (`t[0]`)\n",
    ">   to be whatever the value of the `expression` grammar (`t[2]`) \n",
    ">   that follows the `'SUCC'` operator (`t[1]`) plus 1.\n",
    "\n",
    "\n",
    "* * *\n",
    "\n",
    "\n",
    "## Question 3b: The `test_strings` and their results below: _(16pts)_\n",
    "\n",
    "```\n",
    "    test_strings = ['2+3', '2+!-3', '3 + 3 * -!!3 + !3 * !!!-3', 'x=3', 'y=4', 'z=x+y', 'z', 'z=x+!y', 'z']\n",
    "```\n",
    "\n",
    "### ANSWERS:\n",
    "\n",
    ">### String 0:\n",
    "        '2+3'\n",
    ">### Results:\n",
    ">> $5$\n",
    "\n",
    "\n",
    "<!-- -->\n",
    ">### String 1:\n",
    "        '2+!-3'\n",
    ">### Results:\n",
    ">> $0$\n",
    "\n",
    "\n",
    "<!-- -->\n",
    ">### String 2:\n",
    "        '3 + 3 * -!!3 + !3 * !!!-3'\n",
    ">### Results:\n",
    ">> $-12$\n",
    "\n",
    "\n",
    "<!-- -->\n",
    ">### String 3:\n",
    "        'x=3'\n",
    ">### Results:\n",
    ">> Technically no result was outputted, but it set the value of `x` to be $3$.\n",
    "\n",
    "\n",
    "<!-- -->\n",
    ">### String 4:\n",
    "        'y=4'\n",
    ">### Results:\n",
    ">> Technically no result was outputted, but it set the value of `y` to be $4$.\n",
    "\n",
    "\n",
    "<!-- -->\n",
    ">### String 5:\n",
    "        'z=x+y'\n",
    ">### Results:\n",
    ">> Technically no result was outputted, but it set the value of `z` to be `x+y` ($7$).\n",
    "\n",
    "\n",
    "<!-- -->\n",
    ">### String 6:\n",
    "        'z'\n",
    ">### Results:\n",
    ">> $7$\n",
    "\n",
    "\n",
    "<!-- -->\n",
    ">### String 7:\n",
    "        'z=x+!y'\n",
    ">### Results:\n",
    ">> Technically no result was outputted, but it set the value of `z` to be $8$.\n",
    "\n",
    "\n",
    "<!-- -->\n",
    ">### String 8:\n",
    "        'z'\n",
    ">### Results:\n",
    ">> $8$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "* * *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **XL _(Partly filled answers below)_**\n",
    "\n",
    "## Question 4a: _(8pts)_\n",
    "\n",
    "### **Prompt:** How did ```c* & !b``` get parsed?\n",
    "_**HINT:** \n",
    "  Nullability rules from Section 10.2.2 of the book used to conclude the nullability status. \n",
    "  You could use phrases such as: `nullability of RE1 & RE2 is true if ..., nullability of !R is true if ...`, etc._\n",
    "#### ANSWER: \n",
    "  > \n",
    "  - `!` has the highest precedence \n",
    "    and is right associative,\n",
    "    and so binds to `\"b\"` first.\n",
    "  - `*` has a higher precedence than `&` \n",
    "    and is left associative, \n",
    "    and so binds to `\"c\"`.\n",
    "  - Rule for Conjunction : both must be nullable.\n",
    "    - Rule for Klein Star : always nullable.\n",
    "      - Therefore `\"c*\"` is nullable.\n",
    "    - Rule for Not : if operand expression is not nullable.\n",
    "      - Rule for string/char (not $\\varepsilon$): never nullable.\n",
    "        - Therefore `\"b\"` is not nullable.\n",
    "      - Therefore `\"!b\"` is nullable\n",
    "    - Therefore `\"c* & !b\"` is nullable.\n",
    "\n",
    "* * *\n",
    "\n",
    "\n",
    "## Question 4b: _(8pts)_\n",
    "\n",
    "### **Prompt:** How did ```c* & b*``` get parsed?\n",
    "_**Tip:** \n",
    "  Nullability rules from Section 10.2.2 of the book used to conclude the nullability status. \n",
    "  You could use phrases such as: `nullability of RE1 & RE2 is true if ..., nullability of !R is true if ...`, etc._\n",
    "#### ANSWER:\n",
    "  > \n",
    "  - The `*`'s have a higher precedence than `&` \n",
    "    and are left associative, \n",
    "    and therefore bind to `\"c\"` & `\"b\"` respectively.\n",
    "  - Rule for Conjunction : both must be nullable.\n",
    "    - Rule for Klein Star : always nullable.\n",
    "      - Therefore `\"c*\"` is nullable.\n",
    "    - Rule for Kline Star : always nullable.\n",
    "      - Therefore `\"b*\"` is nullable.\n",
    "    - Therefore `\"c* & !b\"` is nullable.\n",
    "\n",
    "* * *\n",
    "\n",
    "\n",
    "## Question 4c: _(9pts)_\n",
    "\n",
    "### **Prompt:** Why did `(a+bc+def+bd)*` match `bc`? \n",
    "_**HINT:** \n",
    "  Remember that an RE `R` matches a string `w` if the derivative of R via w is nullable. \n",
    "  You will be mentioning the applicable derivative rules from **Figure 10.2**.  \n",
    "  You can obtain derivatives for whole strings and summations at-once using Rule-1 multiple times. \n",
    "  For instance, to derive `(ab+cd)` on string `ab`, \n",
    "    just state: `using Rules 7 and 1, we can derive an ε.`_\n",
    "#### ANSWER: \n",
    "> \n",
    "- Obtain the derivative of `(a+bc+def+bd)*` \n",
    "  $\\xrightarrow{\\varepsilon}$ `(a+bc+def+bd)(a+bc+def+bd)*`\n",
    "- Obtain the derivative of `(a+bc+def+bd)`\n",
    "  $\\xrightarrow{\\varepsilon}$ `a+(bc+def+bd)`\n",
    "- Obtain the derivative of `(bc+def+bd)`\n",
    "  $\\xrightarrow{\\varepsilon}$ `bc+(def+bd)`\n",
    "- Obtain the derivative of `bc`\n",
    "  $\\xrightarrow{b}$ `εc`\n",
    "- Obtain the derivative of `c`\n",
    "  $\\xrightarrow{c}$ $\\varepsilon$\n",
    "- $\\varepsilon$ is nullable.\n",
    "- Hence ```(a+bc+def+bd)*``` matches ```bc```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "* * *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "121px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  },
  "widgets": {
   "state": {
    "430c92ee02b34ec1912bf03c8de1e6dc": {
     "views": [
      {
       "cell_index": 20
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}