{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources on PLY\n",
    "\n",
    " \n",
    "## Documentation of PLY is here: https://www.dabeaz.com/ply/ply.html\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This Youtube video is a talk by David Beazley, the author of PLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "# Direct path is https://youtu.be/zJ9z6Ge-vXs\n",
    "YouTubeVideo('zJ9z6Ge-vXs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## This Youtube video is a talk on creating a calculator using PLY\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "# Direct path is  https://youtu.be/Hh49BXmHxX8\n",
    "YouTubeVideo('Hh49BXmHxX8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THIS NOTEBOOK is referenced in Asg-6\n",
    "# It Creates a RegExp Parser + Draw Parse Trees\n",
    "\n",
    "# YOUR QUESTIONS are at the end!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "import sys\n",
    "\n",
    "# -- Detect if in Own Install or in Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    OWN_INSTALL = False\n",
    "except:\n",
    "    OWN_INSTALL = True\n",
    "    \n",
    "if OWN_INSTALL:\n",
    "    \n",
    "  #---- Leave these definitions ON if running on laptop\n",
    "  #---- Else turn OFF by putting them between ''' ... '''\n",
    "\n",
    "  sys.path[0:0] = ['../../../../..',  '../../../../../3rdparty',  \n",
    "                   '../../../..',  '../../../../3rdparty',  \n",
    "                   '../../..',     '../../../3rdparty', \n",
    "                   '../..',        '../../3rdparty',\n",
    "                   '..',           '../3rdparty' ]\n",
    "\n",
    "else: # In colab\n",
    "  ! if [ ! -d Jove ]; then git clone https://github.com/ganeshutah/Jove Jove; fi\n",
    "  sys.path.append('./Jove')\n",
    "  sys.path.append('./Jove/jove')\n",
    "\n",
    "# -- common imports --\n",
    "from jove.lex import lex\n",
    "from jove.yacc import yacc\n",
    "\n",
    "from jove.StateNameSanitizers import ResetStNum, NxtStateStr\n",
    "from jove.SystemImports       import *\n",
    "\n",
    "from jove.Def_NFA import mk_nfa\n",
    "from jove.DotBashers import *\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "tokens = ('EPS','STR','LPAREN','RPAREN','PLUS','STAR')  \n",
    "\n",
    "# Tokens in our RE are these\n",
    "t_EPS     = r'\\'\\'|\\\"\\\"'  # Not allowing @ for empty string anymore! # t_EPS = r'\\@'\n",
    "\n",
    "# The following allows one lower-case, one upper-case or one digit to be used in our REs\n",
    "t_STR     = r'[a-zA-Z0-9]'\n",
    "\n",
    "t_LPAREN  = r'\\('\n",
    "t_RPAREN  = r'\\)'\n",
    "\n",
    "t_PLUS    = r'\\+'\n",
    "t_STAR    = r'\\*'\n",
    "\n",
    "\n",
    "\n",
    "# Ignored characters\n",
    "t_ignore = \" \\t\"\n",
    "\n",
    "def t_newline(t):\n",
    "    r'\\n+'\n",
    "    t.lexer.lineno += t.value.count(\"\\n\")\n",
    "    \n",
    "def t_error(t):\n",
    "    print(\"Illegal character '%s'\" % t.value[0])\n",
    "    t.lexer.skip(1)\n",
    "    \n",
    "\n",
    "def p_expression_plus(t):\n",
    "    'expression : expression PLUS catexp'\n",
    "    #\n",
    "    nfa = mk_plus_nfa(t[1]['nfa'], t[3]['nfa']) # Union of the two NFAs is returned\n",
    "    tree = attrDyadicInfix(\"+\", t[1], t[3])\n",
    "    tree.update({'nfa':nfa})\n",
    "    t[0] = tree\n",
    "    \n",
    "\n",
    "def p_expression_plus1(t):\n",
    "    'expression : catexp'\n",
    "    #\n",
    "    t[0] = t[1]  \n",
    "\n",
    "def p_expression_cat(t):\n",
    "    'catexp :  catexp ordyexp'\n",
    "    #\n",
    "    nfa = mk_cat_nfa(t[1]['nfa'], t[2]['nfa'])\n",
    "    #--insert new field 'nfa'\n",
    "    tree = attrDyadicInfix(\".\", t[1], t[2])\n",
    "    tree.update({'nfa':nfa})\n",
    "    t[0] = tree\n",
    "\n",
    "def p_expression_cat1(t):\n",
    "    'catexp :  ordyexp'\n",
    "    #\n",
    "    t[0] = t[1] \n",
    "\n",
    "# We employ field 'ast' of the dict to record the abstract syntax tree. \n",
    "# Field 'dig' holds a digraph. It too is a dict. \n",
    "# Its fields are nl for the node list and el for the edge list\n",
    "\n",
    "def p_expression_ordy_star(t):\n",
    "    'ordyexp : ordyexp STAR'\n",
    "    #\n",
    "    nfa = mk_star_nfa(t[1]['nfa'])\n",
    "    \n",
    "    ast = ('*', t[1]['ast'])\n",
    "    nlin = t[1]['dig']['nl']\n",
    "    elin = t[1]['dig']['el']\n",
    "    \n",
    "    rootin = nlin[0]\n",
    "\n",
    "    root = NxtStateStr(\"R*_\") \n",
    "    right = NxtStateStr(\"*_\")\n",
    "\n",
    "    t[0] = {'nfa' : nfa,\n",
    "            'ast' : ast,\n",
    "            'dig' : {'nl' : [root] + nlin + [right], # this order important for proper layout!\n",
    "                     'el' : elin + [ (root, rootin),\n",
    "                                     (root, right) ]\n",
    "                    }}\n",
    "    \n",
    "def p_expression_ordy_paren(t):\n",
    "    'ordyexp : LPAREN expression RPAREN'\n",
    "    #\n",
    "    nfa  = t[2]['nfa']\n",
    "    \n",
    "    ast  = t[2]['ast']\n",
    "    nlin = t[2]['dig']['nl']\n",
    "    elin = t[2]['dig']['el']\n",
    "    \n",
    "    rootin = nlin[0]\n",
    "    \n",
    "    root = NxtStateStr(\"(R)_\")\n",
    "    left = NxtStateStr(\"(_\")\n",
    "    right= NxtStateStr(\")_\")\n",
    "    \n",
    "    t[0] = {'nfa' : nfa,\n",
    "            'ast' : ast,\n",
    "            'dig' : {'nl' : [root, left] + nlin + [right], #order important f. proper layout!\n",
    "                     'el' : elin + [ (root, left),\n",
    "                                     (root, rootin),\n",
    "                                     (root, right) ]\n",
    "                    }}\n",
    "    \n",
    "def p_expression_ordy_eps(t):\n",
    "    'ordyexp : EPS'\n",
    "    #\n",
    "    strn = '@'\n",
    "    ast  = ('@', strn)           \n",
    "    t[0] = { 'nfa' : mk_eps_nfa(),\n",
    "             'ast' : ast,\n",
    "             'dig' : {'nl' : [ strn + NxtStateStr(\"_\") ],\n",
    "                      'el' : []\n",
    "                     }} \n",
    "    \n",
    "def p_expression_ordy_str(t):\n",
    "    'ordyexp : STR'\n",
    "    #\n",
    "    str = t[1]\n",
    "    nfa_STR = mk_symbol_nfa(t[1])\n",
    "    ast  = ('str', str)\n",
    "    t[0] = {'nfa' : nfa_STR,\n",
    "            'ast' : ast,\n",
    "            'dig' : {'nl' : [ str + NxtStateStr(\"_\") ],\n",
    "                     'el' : [] \n",
    "                    }}\n",
    "    \n",
    "def p_error(t):\n",
    "    print(\"Syntax error at '%s'\" % t.value)\n",
    "\n",
    "#--\n",
    "def parseRE(s):\n",
    "    \"\"\"In: a string s containing a regular expression.\n",
    "       Out: An attribute quadruple (nfa,ast,nodelist,edgelist)        \n",
    "    \"\"\"\n",
    "    mylexer  = lex()\n",
    "    myparser = yacc()\n",
    "    #-- pass the right lexer into the parser    \n",
    "    p = myparser.parse(s, lexer = mylexer)  \n",
    "    return (p['nfa'], p['ast'], p['dig']['nl'], p['dig']['el']) \n",
    "\n",
    "#--\n",
    "def mk_plus_nfa(N1, N2):\n",
    "    \"\"\"Given two NFAs, return their union.\n",
    "    \"\"\"\n",
    "    delta_accum = dict({})\n",
    "    delta_accum.update(N1[\"Delta\"])\n",
    "    delta_accum.update(N2[\"Delta\"]) # Simply accumulate the transitions\n",
    "    # The alphabet is inferred bottom-up; thus we must union the Sigmas \n",
    "    # of the NFAs!\n",
    "    return mk_nfa(Q     = N1[\"Q\"] | N2[\"Q\"], \n",
    "                  Sigma = N1[\"Sigma\"] | N2[\"Sigma\"], \n",
    "                  Delta = delta_accum, \n",
    "                  Q0    = N1[\"Q0\"] | N2[\"Q0\"], \n",
    "                  F     = N1[\"F\"] | N2[\"F\"])  \n",
    "\n",
    "def mk_cat_nfa(N1, N2):\n",
    "    '''Given two NFAs, return their concatenation.\n",
    "    '''\n",
    "    delta_accum = dict({}) \n",
    "    delta_accum.update(N1[\"Delta\"])\n",
    "    delta_accum.update(N2[\"Delta\"])\n",
    "    # Now, introduce moves from every one of N1's final states\n",
    "    # to the set of N2's initial states.\n",
    "    for f in N1[\"F\"]:\n",
    "        # However, N1's final states may already have epsilon moves to\n",
    "        # other N1-states!\n",
    "        # Expand the target of such jumps to include N2's Q0 also!\n",
    "        if (f, \"\") in N1[\"Delta\"]: \n",
    "            delta_accum.update({ (f,\"\"):(N2[\"Q0\"] | N1[\"Delta\"][(f, \"\")])\n",
    "                               })\n",
    "        else:\n",
    "            delta_accum.update({ (f, \"\"): N2[\"Q0\"] })\n",
    "    # In syntax-directed translation, it is impossible\n",
    "    # that N2 and N1 have common states. Check anyhow\n",
    "    # in case there are bugs elsewhere that cause it.\n",
    "    assert((N2[\"F\"] & N1[\"F\"]) == set({})) \n",
    "    return mk_nfa(Q     = N1[\"Q\"] | N2[\"Q\"], \n",
    "                  Sigma = N1[\"Sigma\"] | N2[\"Sigma\"], \n",
    "                  Delta = delta_accum, \n",
    "                  Q0    = N1[\"Q0\"],\n",
    "                  F     = N2[\"F\"])\n",
    "\n",
    "\n",
    "def mk_star_nfa(N):\n",
    "    '''Given an NFA, make its star.\n",
    "    '''\n",
    "    # Follow construction from Kozen's book:\n",
    "    # 1) Introduce new (single) start+final state IF\n",
    "    # 2) Let Q0 = set({ IF })\n",
    "    # 2) Move on epsilon from IF to the set N[Q0]\n",
    "    # 3) Make N[F] non-final\n",
    "    # 4) Spin back from every state in N[F] to Q0\n",
    "    #\n",
    "    delta_accum = dict({})\n",
    "    IF = NxtStateStr()\n",
    "    Q0 = set({ IF }) # new set of start + final states\n",
    "    # Jump from IF to N's start state set\n",
    "    delta_accum.update({ (IF,\"\"): N[\"Q0\"] })\n",
    "    delta_accum.update(N[\"Delta\"])\n",
    "    #\n",
    "    for f in N[\"F\"]:\n",
    "        # N's final states may already have epsilon moves to\n",
    "        # other N-states!\n",
    "        # Expand the target of such jumps to include Q0 also.\n",
    "        if (f, \"\") in N[\"Delta\"]:\n",
    "            delta_accum.update({ (f, \"\"): (Q0 | N[\"Delta\"][(f, \"\")]) })\n",
    "        else:\n",
    "            delta_accum.update({ (f, \"\"): Q0 })\n",
    "    #\n",
    "    return mk_nfa(Q     = N[\"Q\"] | Q0, \n",
    "                  Sigma = N[\"Sigma\"], \n",
    "                  Delta = delta_accum, \n",
    "                  Q0    = Q0, \n",
    "                  F     = Q0)\n",
    "\n",
    "\n",
    "def mk_eps_nfa():\n",
    "    \"\"\"An nfa with exactly one start+final state, which is the NFA for Epsilon.\n",
    "    \"\"\"\n",
    "    Q0 = set({ NxtStateStr() })\n",
    "    F  = Q0\n",
    "    return mk_nfa(Q     = Q0, \n",
    "                  Sigma = set({}), \n",
    "                  Delta = dict({}), \n",
    "                  Q0    = Q0, \n",
    "                  F     = Q0)                      \n",
    "\n",
    "def mk_symbol_nfa(a):\n",
    "    \"\"\"The NFA for a single re letter.\n",
    "    \"\"\"\n",
    "    # Make a fresh initial state\n",
    "    q0 = NxtStateStr()\n",
    "    Q0 = set({ q0 })\n",
    "    # Make a fresh final state\n",
    "    f = NxtStateStr()\n",
    "    F = set({ f })\n",
    "    return mk_nfa(Q     = Q0 | F, \n",
    "                  Sigma = set({a}), \n",
    "                  Delta = { (q0,a): F },\n",
    "                  Q0    = Q0, \n",
    "                  F     = F)\n",
    "                                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attrDyadicInfix(op, attr1, attr3):         # <== this is what prints the parse-tree\n",
    "    ast  = (op, (attr1['ast'], attr3['ast']))  # <== for an infix operator\n",
    "    \n",
    "    nlin1 = attr1['dig']['nl']\n",
    "    nlin3 = attr3['dig']['nl']\n",
    "    nlin  = nlin1 + nlin3\n",
    "    \n",
    "    elin1 = attr1['dig']['el']\n",
    "    elin3 = attr3['dig']['el']\n",
    "    elin  = elin1 + elin3\n",
    "    \n",
    "    rootin1 = nlin1[0]\n",
    "    rootin3 = nlin3[0]    \n",
    "    \n",
    "    root   = NxtStateStr(\"R1\"+op+\"R2\"+\"_\") # NxtStateStr(\"$_\")\n",
    "    left   = rootin1\n",
    "    middle = NxtStateStr(op+\"_\")\n",
    "    right  = rootin3\n",
    "    \n",
    "    return {'ast' : ast,\n",
    "            'dig' : {'nl' : [ root, left, middle, right ] + nlin,\n",
    "                     'el' : elin + [ (root, left),\n",
    "                                     (root, middle),\n",
    "                                     (root, right) ]\n",
    "                     }}\n",
    "\n",
    "\n",
    "def drawPT(nfa_ast_nl_el, comment=\"PT\"):\n",
    "    \"\"\"Given an (nfa, ast, nl, el) quadruple where nl is the node and el the edge-list,\n",
    "       draw the Parse Tree by returning a dot object. Also return the NFA dot object.\n",
    "    \"\"\"\n",
    "    (nfa, ast, nl, el) = nfa_ast_nl_el\n",
    "    print(\"Drawing AST for \", ast)\n",
    "    dotObj_pt = Digraph(comment)\n",
    "    dotObj_pt.graph_attr['rankdir'] = 'TB'\n",
    "    for n in nl:\n",
    "        prNam = n.split('_')[0]\n",
    "        dotObj_pt.node(n, prNam, shape=\"oval\", peripheries=\"1\")\n",
    "    for e in el:\n",
    "        dotObj_pt.edge(e[0], e[1])\n",
    "    return (dotObj_nfa(nfa), dotObj_pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Now answer these questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parseRE(\"''\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(n,t) = drawPT(parseRE(\"''\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(n1,t1) = drawPT(parseRE(\"(a*b*+cc)*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(n2,t2) = drawPT(parseRE(\"(a*b)*+cc*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# YOUR QUESTIONS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1: Run this notebook as follows\n",
    "\n",
    "## 1) Restart remove the parsetab.py file and __pycache__/\n",
    "\n",
    "## 2) Run all the cells (ignore warnings such as this)\n",
    "\n",
    "#### WARNING: ../../../../jove/TransitionSelectors.py:22: Possible grammar rule 'fn_range' defined without p_ prefix\n",
    "\n",
    "## 3) Look at the productions (the ```p_``` functions) and write down a context-free grammar for parsing regular expressions\n",
    "\n",
    "### YOUR ANSWER may please be written in this style, (inventing suitable abbreviations to express the High-level Rule)\n",
    "\n",
    "* expression : expression PLUS catexpression\n",
    "  - High-level Rule: R -> R + C  \n",
    "  \n",
    "* Do this for all the rules\n",
    "\n",
    "* When you have things like LPAREN, look up how the token was encoded, and write `(` instead in the High-level Rule\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2: Execute these commands:\n",
    "\n",
    "* (n1,t1) = drawPT(parseRE(\"(a*b*+cc)*\"))\n",
    "\n",
    "* (n2,t2) = drawPT(parseRE(\"(a*b)*+cc*\"))\n",
    "\n",
    "## By comparing n1 and t1, justify that the correct NFA formation rules have been followed\n",
    "\n",
    "## Repeat for n2 and t2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3: Explain the workings of all the mk_X_nfa functions by arguing that they are making the right output NFA from the input NFA. \n",
    "\n",
    "## In your explanation, explain how Q, Sigma, Delta, q0, and F are formed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
